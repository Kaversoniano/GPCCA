% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GPCCAselect.R
\name{GPCCAselect}
\alias{GPCCAselect}
\title{Select the Target Dimension for GPCCA Model}
\usage{
GPCCAselect(
  X.list,
  d.set = 2:5,
  lambda = 0.5,
  tol = 1e-04,
  maxiter = 100,
  EarlyStop = TRUE,
  niter.ES = 5,
  force_blkInv = TRUE,
  W.init = "rand.std.norm",
  missVal = TRUE,
  diagCov = FALSE,
  B = 5,
  seed = 1234,
  N.cores = 1
)
}
\arguments{
\item{X.list}{a list of numeric matrices. A multi-modal dataset of \eqn{R} 
modalities, where each matrix \eqn{\mathbf{X}^{(r)}} is a data modality, 
with \eqn{m_r} rows denoting features and \eqn{n} columns denoting samples 
(\eqn{1 \le r \le R}). All modalities must have the same sample size \eqn{n}, 
with the ordering of samples matched to each other. Artificial modality-wise 
missing values should be introduced by the user if non-matching samples are present.}

\item{d.set}{an integer vector. A set of candidate values for the size of 
target dimension \eqn{d}, i.e. the number of latent factors 
in low-dimensional subspace. (Default: \code{2:5})}

\item{lambda}{a numeric scalar. The ridge regularization parameter \eqn{\lambda}, 
in the range of \eqn{(0, 1]}. A smaller \eqn{\lambda} corresponds to heavier 
penalty, which leads to a more sparse (diagonal-like) structure of the 
error covariance matrix \eqn{\mathbf{\Psi}}. In the extreme case, 
\eqn{\lambda = 1} means no ridge regularization is applied. 
It affects nothing if \code{diagCov = TRUE}. (Default: \code{0.5})}

\item{tol}{a numeric scalar. Tolerance of the RMSE measuring the difference 
in the matrix of latent factors \eqn{\mathbf{Z}} between two consecutive 
iterations. This tolerance threshold \eqn{\tau} determines the stopping rule 
of the EM algorithm, and the RMSE is used to monitor the convergence.
(Default: \code{0.0001})}

\item{maxiter}{an integer. The maximum number of iterations allowed in the 
EM algorithm. (Default: \code{100})}

\item{EarlyStop}{a logical. Should early stop be used? If set to \code{TRUE}, 
it stops the EM algorithm early. With early stop turned on, only sub-optimal 
solution may be attained, but it helps avoid overfitting. (Default: \code{TRUE})}

\item{niter.ES}{an integer. The number of consecutive increase of RMSE allowed 
to decide for early stop. It affects nothing if \code{EarlyStop = FALSE}. 
(Default: \code{5})}

\item{force_blkInv}{a logical. Should blockwise inversion of the error 
covariance matrix \eqn{\mathbf{\Psi}} be activated? A technique to boost 
computation. It is automatically turned on if either the dimension of any 
data modality \eqn{m_r} is larger than \eqn{500} or the total dimension 
\eqn{m = \sum_{r=1}^{R}m_r} is larger than \eqn{1000}. 
It affects nothing if \code{diagCov = TRUE}. (Default: \code{TRUE})}

\item{W.init}{One of \code{"PCA"} and \code{"rand.std.norm"}, 
indicating which method is used for initializing the loading matrix 
\eqn{\mathbf{W}}. \code{"rand.std.norm"} initializes all elements of 
\eqn{\mathbf{W}} with i.i.d. standard normal random variates. \code{"PCA"} 
uses Randomized Principal Component Analysis (RPCA) if all data modalities 
are complete without missingness or Probabilistic Principal Component Analysis 
(PPCA) if any missing value is present in the multi-modal data \code{X.list}. 
(Default: \code{"rand.std.norm"})}

\item{missVal}{a logical. Does the input multi-modal data \code{X.list} 
contain any missing value \code{NA}? If \code{X.list} is known to contain 
no missing value, setting \code{missVal = FALSE} can reduce runtime 
significantly. (Default: \code{TRUE})}

\item{diagCov}{a logical. Should the strict diagonal structure be used for 
the error covariance matrix \eqn{\mathbf{\Psi}}? It is only recommended 
when the total dimension of data \eqn{m} (total number of features) is 
extremely large. (Default: \code{FALSE})}

\item{B}{an integer. The number of different initializations \eqn{B} 
to be used for model selection. (Default: \code{5})}

\item{seed}{an integer. The seed for random number generation. 
Set the seed for exact reproduction of your results. (Default: \code{1234})}

\item{N.cores}{an integer. The number of cores to use for parallel computing. 
It is suggested to set it equal to the number of initializations \eqn{B}. 
Must be exactly \eqn{1} on Windows, which uses the master process. 
(Default: \code{1})}
}
\value{
A list of 2 is returned, including:
\describe{
  \item{\code{consensus.score}}{a named numeric vector; stores the consensus 
    scores under all candidate values for the target dimension.}
  \item{\code{optim.d}}{an integer (vector); gives the optimal choice(s) 
    of the target dimension.}
}
}
\description{
Generalized Probabilistic Canonical Correlation Analysis (GPCCA) involves two 
  hyper-parameters: the size of target dimension \eqn{d} and the ridge 
  regularization parameter \eqn{\lambda}. \code{GPCCAselect} provides a 
  built-in technique for selecting the best \eqn{d} given a set of candidates. 
  This model selection framework is computationally intensive when the 
  dimensionality of data is considerably high. Thus it is recommended to 
  perform such model selection on a subset of data samples using highly 
  informative features only.
  
  The default value \eqn{\lambda = 0.5} leads to good performance in general, 
  but there is no built-in method for selecting \eqn{\lambda} due to the 
  unsupervised nature of GPCCA. Users may need to use a customized measure of 
  performance and find the optimal \eqn{\lambda} adaptively. 
  See \code{\link{GPCCAmodel}} for more details of the GPCCA model.
}
\details{
\bold{Model selection on target dimension:} 
  The size of target dimension \eqn{d} (the number of latent factors) is a 
  hyper-parameter of GPCCA model. Given a set of candidate values 
  \eqn{d_1 < d_2 < \dots < d_G}, for each \eqn{d_g}, \eqn{B} different 
  initializations are used to fit the model. With Louvain clustering on the 
  fitted latent factors, the \eqn{B} clustering results are aggregated into 
  a matrix \eqn{\mathbf{L}_g \in \text{R}^{n \times B}}. Then, the consensus 
  matrix \eqn{\mathbf{C}_g \in \text{R}^{n \times n}} is computed based on 
  \eqn{\mathbf{L}_g}. To assess the consistency of the \eqn{B} clustering 
  results, the following consensus score is defined for measuring 
  the agreement between multiple results under \eqn{d_g}: 
  \deqn{\mathcal{H}_g = \sum\limits_{i<j}\mathbf{C}_{g,ij}\log_2(\mathbf{C}_{g,ij})} 
  And the optimal choice of \eqn{d} is selected as the candidate value 
  \eqn{d_{g^*}} which corresponds to the highest consensus score: 
  \deqn{g^* = \text{argmax}_{1 \le g \le G}\mathcal{H}_g}
}
\examples{
\dontrun{

## I: Select the target dimension for GPCCA model on incomplete data
## (`GPCCAmodel` can handle both complete and incomplete data)
DAT <- example_MultiModalData_sim(missVal = TRUE)
GPCCA.ds <- GPCCAselect(X.list = DAT,
                        d.set = c(2, 4, 6, 8, 10),
                        B = 5, seed = 1234, N.cores = 5)

## II: Select the target dimension for GPCCA model on complete data
## (`GPCCAmodel` can handle both complete and incomplete data)
DAT <- example_MultiModalData_sim(missVal = FALSE)
GPCCA.ds <- GPCCAselect(X.list = DAT,
                        d.set = c(2, 4, 6, 8, 10),
                        B = 5, seed = 1234, N.cores = 5)

## III: Select the target dimension for GPCCA model on complete data
## (setting `missVal = FALSE` explicitly to reduce runtime)
DAT <- example_MultiModalData_sim(missVal = FALSE)
GPCCA.ds <- GPCCAselect(X.list = DAT,
                        d.set = c(2, 4, 6, 8, 10), missVal = FALSE,
                        B = 5, seed = 1234, N.cores = 5)

## Output consensus scores under varying target dimensions
GPCCA.ds$consensus.score

## Output the optimal choice(s) of target dimension
GPCCA.ds$optim.d
}
}
\seealso{
\code{\link{GPCCAmodel}}, \code{\link{EM_completeDAT}}, 
  \code{\link{EM_missingDAT}}, \code{\link{EM_diagonalCOV}}
}
